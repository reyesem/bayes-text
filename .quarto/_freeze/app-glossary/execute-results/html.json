{
  "hash": "2a4667322e5166e1c3b286d34d039062",
  "result": {
    "markdown": "# Glossary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\providecommand{\\norm}[1]{\\lVert#1\\rVert}\n\\providecommand{\\abs}[1]{\\lvert#1\\rvert}\n\\providecommand{\\iid}{\\stackrel{\\text{IID}}{\\sim}}\n\\providecommand{\\ind}{\\stackrel{\\text{Ind}}{\\sim}}\n  \n\\providecommand{\\bm}[1]{\\mathbf{#1}}\n\\providecommand{\\bs}[1]{\\boldsymbol{#1}}\n\\providecommand{\\bbeta}{\\bs{\\beta}}\n  \n\\providecommand{\\Ell}{\\mathcal{L}}\n\\providecommand{\\indep}{\\perp\\negthickspace\\negmedspace\\perp}\n\n\n\nThe following key terms were defined in the text; each term is presented with a link to where the term was first encountered in the text.\n\n\nAlternative Hypothesis (@def-alternative-hypothesis) \n: The statement (or theory) about the parameter capturing what we would like to provide evidence _for_; this is the opposite of the null hypothesis.  This is denoted $H_1$ or $H_a$, read \"H-one\" and \"H-A\" respectively.\n\nAverage (@def-average) \n: Also known as the \"mean,\" this measure of location represents the balance point for the distribution.  If $x_i$ represents the $i$-th value of the variable $x$ in the sample, the sample mean is typically denoted by $\\bar{x}$.  \n\nFor a sample of size $n$, it is computed by\n$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i.$$\n\nWhen referencing the average for a population, the mean is also called the \"Expected Value,\" and is often denoted by $\\mu$.\n\nAxioms of Probability (@def-axioms) \n: Let $\\mathcal{S}$ be the sample space of a random process.  Suppose that to each event $A$ within $\\mathcal{S}$, a number denoted by $Pr(A)$ is associated with $A$.  If the map $Pr(\\cdot)$ satisfies the following three axioms, then it is called a __probability__:\n\n  1. $Pr(A) \\geq 0$\n  2. $Pr(\\mathcal{S}) = 1$\n  3. If $\\left\\{A_1, A_2, \\dotsc\\right\\}$ is a sequence of mutually exclusive events in $\\mathcal{S}$, then\n  \n  $$Pr\\left(\\bigcup_{i = 1}^{\\infty} A_i\\right) = \\sum_{i = 1}^{\\infty} Pr\\left(A_i\\right).$$\n  \n\n\n$Pr(A)$ is said to be the \"probability of $A$\" or the \"probability $A$ occurs.\"\n\nBayes Factor (@def-bayes-factor) \n: A measure of how the observed data _alters_ your prior beliefs about a hypothesis.  Let $H_j$ denote the hypothesis that $\\theta \\in \\Theta_j$ for some region $\\Theta_j$.  The Bayes Factor _in favor of_ $H_j$ is the ratio of the posterior odds in favor of $H_j$ to the prior odds in favor of $H_j$:\n\n$$BF_j = \\left(\\frac{Pr\\left(\\theta \\in \\Theta_j \\mid \\bm{y}\\right)}{Pr\\left(\\theta \\notin \\Theta_j \\mid \\bm{y}\\right)}\\right)\\left(\\frac{Pr\\left(\\theta \\notin \\Theta_j\\right)}{Pr\\left(\\theta \\in \\Theta_j\\right)}\\right).$$\n\nBayes Factor for Model Comparison (@def-bayes-factor-models) \n: The Bayes Factor, in favor of Model 1, is\n\n$$\n\\begin{aligned}\n  BF_{1} &= \\left(\\frac{Pr(\\mathcal{M}_1 \\mid \\bm{y})}{Pr(\\mathcal{M}_0 \\mid \\bm{y})}\\right)\\left(\\frac{Pr(\\mathcal{M}_0)}{Pr(\\mathcal{M}_1)}\\right) \\\\\n    &= \\left(\\frac{f_1(\\bm{y} \\mid \\mathcal{M}_1) Pr(\\mathcal{M}_1)}{f_0(\\bm{y} \\mid \\mathcal{M}_0) Pr(\\mathcal{M}_0)}\\right)\\left(\\frac{Pr(\\mathcal{M}_0)}{Pr(\\mathcal{M}_1)}\\right) \\\\\n    &= \\frac{f_1(\\bm{y} \\mid \\mathcal{M}_1)}{f_0(\\bm{y} \\mid \\mathcal{M}_0)}.\n\\end{aligned}\n$$\n\nThat is, the Bayes Factor is a ratio of the evidence for each model.\n\nBias (@def-bias) \n: A set of measurements is said to be biased if they are _consistently_ too high (or too low).  Similarly, an estimate of a parameter is said to be biased if it is _consistently_ too high (or too low).\n\nBlocking (@def-blocking) \n: Blocking is a way of minimizing the variability contributed by an inherent characteristic that results in dependent observations.  In some cases, the blocks are the unit of observation which is sampled from a larger population, and multiple observations are taken on each unit.  In other cases, the blocks are formed by grouping the units of observations according to an inherent characteristic; in these cases that shared characteristic can be thought of having a value that was sampled from a larger population.\n\nIn both cases, the observed blocks can be thought of as a random sample; within each block, we have multiple observations, and the observations from the same block are more similar than observations from different blocks.\n\nBridge Sampling (@def-bridge-sampling) \n: The bridge sampling estimator of the marginal likelihood $m(\\bm{y})$ is given by\n\n$$\n\\begin{aligned}\n  m(\\bm{y}) \n    &= \\int f(\\bm{y} \\mid \\bs{\\theta}) \\pi(\\bs{\\theta}) d\\bs{\\theta} \\\\\n    &= \\frac{E_g\\left[h(\\bs{\\theta}) f(\\bm{y} \\mid \\bs{\\theta}) \\pi(\\bs{\\theta})\\right]}{E_{\\pi}\\left[h(\\bs{\\theta}) g(\\bs{\\theta}) \\right]} \\\\\n    &\\approx \\frac{m^{-1}\\sum_{j=1}^{m} h\\left(\\tilde{\\bs{\\theta}}_j\\right) f\\left(\\bm{y} \\mid \\tilde{\\bs{\\theta}}_j\\right) \\pi\\left(\\tilde{\\bs{\\theta}}_j\\right)}{m^{-1}\\sum_{i=1}^{m} h\\left(\\bs{\\theta}^*_j\\right) g\\left(\\bs{\\theta}^*_j\\right)}\n\\end{aligned}\n$$\n   \nwhere $h(\\bs{\\theta})$ is called the bridge function and $g(\\bs{\\theta})$ is the proposal distribution.  Here, $\\tilde{\\bs{\\theta}}$ denotes a random variate from the proposal distribution and $\\bs{\\theta}^*$ a random variate from the posterior; $E_g$ denotes taking an expectation with respect to the proposal distribution and $E_\\pi$ denotes taking an expectation with respect to the posterior distribution.\n\nCategorical Variable (@def-categorical) \n: Also called a \"qualitative variable,\" a measurement on a subject which denotes a grouping or categorization.\n\nCodebook (@def-codebook) \n: Also called a \"data dictionary,\" these provide complete information regarding the variables contained within a dataset.\n\nConditional Density (@def-conditional-density) \n: Let $X$ and $Y$ be two random variables; the conditional density of $X$ given $Y$ is \n\n$$f_{X \\mid Y}(y \\mid x) = \\frac{f_{X, Y}(x, y)}{f_Y(y)}$$\n\nConditional Density (@def-conditional-density) \n: Let $\\bm{X}$ be a random vector; without loss of generality, partition $\\bm{X}$ such that\n\n$$\\bm{X} = \\begin{pmatrix} \\bm{X}_1 \\\\ \\bm{X}_2 \\end{pmatrix}$$\n\nwhere $\\bm{X}_1$ represents the first $k$ components and $\\bm{X}_2$ represents the remaining $n-k$ components.  Then, the conditional density of $\\bm{X}_1$ given $\\bm{X}_2$ is \n\n$$f_{\\bm{X}_1 \\mid \\bm{X}_2}(\\bm{x}_1 \\mid \\bm{x}_2) = \\frac{f_{\\bm{X}}(\\bm{x})}{f_{\\bm{X}_2}(\\bm{x}_2)}.$$\n\nConditional Independence (@def-conditional-independence) \n: Two random variables $X$ and $Y$ are said to be independent, conditional on (or \"given\") $Z$ if, and only if,\n\n$$f_{(X,Y) \\mid Z} (x, y \\mid z) = f_{X \\mid Z}(x \\mid z) f_{Y \\mid Z}(y \\mid z).$$\n\nConfounding (@def-confounding) \n: When the effect of a variable on the response is mis-represented due to the presence of a third, potentially unobserved, variable known as a confounder.\n\nConjugate Prior (@def-conjugate-prior) \n: A prior distribution chosen such that the posterior distribution belongs to the same family as the prior distribution, with the (hyper)parameters that govern the family updated based on the observed data.\n\nContinuous and Discrete Random Variable (@def-rvtypes) \n: The random variable $X$ is said to be a discrete random variable if its corresponding support is countable.  The random variable $X$ is said to be a continuous random variable if the corresponding support is uncountable (such as an interval or a union of intervals on the real line).\n\nControlled Experiment (@def-controlled-experiment) \n: A study in which each subject is _randomly_ assigned to one of the groups being compared in the study.\n\nCredible Interval (@def-credible-interval) \n: A $100c$% credible interval is an interval $(a, b)$ such that\n\n$$Pr(a \\leq \\theta \\leq b \\mid \\bm{y}) = \\int_{a}^{b} \\pi(\\theta \\mid \\bm{y})d\\theta = c.$$\n\nCumulative Distribution Function (CDF) (@def-cdf) \n: Let $X$ be a random variable; the cumulative distribution function (CDF) is defined as\n\n$$F(u) = Pr(X \\leq u).$$\n\nFor a continuous random variable, we have that\n\n$$F(u) = \\int_{-\\infty}^{u} f(x) dx$$\n\nimplying that the density function is the derivative of the CDF.  For a discrete random variable\n\n$$F(u) = \\sum_{x \\leq u} f(x).$$\n\nDensity Function (@def-density-function) \n: A density function $f$ relates the values in the support of a random variable with the probability of observing those values.  \n\nLet $X$ be a continuous random variable, then its density function $f$ is the function such that\n\n$$Pr(a \\leq X \\leq b) = \\int_a^b f(x) dx$$\n\nfor any real numbers $a$ and $b$ in the support.\n\nLet $X$ be a discrete random variable, then its density function $f$ is the function such that\n\n$$Pr(X = u) = f(u)$$\n\nfor any real number $u$ in the support.\n\nDirac Delta Function (@def-dirac-delta) \n: The Dirac delta function is the function (not in a rigorous sense) $\\delta$ such that\n\n$$\\int_{-\\infty}^{\\infty} \\delta(x) dx = 1$$\n\nand\n\n$$\\int_{-\\infty}^{\\infty} f(x) \\delta(x) dx = f(0)$$\n\nfor any real-valued function $f$.  \n\nThe Dirac delta function allows us to describe a discrete distribution, which places mass at a single point, as a continuous function on the real line.\n\nDistribution (@def-distribution) \n: The pattern of variability corresponding to a set of values.\n\nDistribution of the Population (@def-distribution-population) \n: The pattern of variability in values of a variable at the population level.  Generally, this is impossible to know, but we might model it.\n\nDistribution of the Sample (@def-distribution-sample) \n: The pattern of variability in the observed values of a variable.\n\nEffective Sample Size (@def-ess) \n: The effective sample size (ESS) is given by\n\n$$ESS = \\frac{N}{1 + 2\\sum_{k=1}^{\\infty} ACF(k)}$$\n\nwhere ACF is the auto-correlation function of degree $k$.\n\nEqual-Tailed Credible Interval (@def-equal-tail-interval) \n: The equal-tailed credible interval, which is probably the most commonly used in practice, chooses endpoints such that\n\n$$Pr(\\theta < a \\mid \\bm{y}) = \\frac{1-c}{2} = Pr(\\theta > b \\mid \\bm{y}).$$\n\nEstimation (@def-estimation) \n: Using the sample to approximate the value of a parameter from the underlying population.\n\nEvent (@def-event) \n: A subset of the sample space that is of particular interest.\n\nEvidence for a Model (@def-evidence) \n: Under the Model Comparison framework defined above, the evidence for model $\\mathcal{M}_j$ is defined as\n\n$$f_j(\\bm{y} \\mid \\mathcal{M}_j) = \\int f_j(\\bm{y} \\mid \\theta_j, \\mathcal{M}_j) \\pi_j(\\theta_j \\mid \\mathcal{M}_j) d\\theta_j.$$\n\nExpectation of a Function (@def-expectation) \n: Let $X$ be a random variable with density function $f$ over the support $\\mathcal{S}$, and let $g$ be a real-valued function.  Then, \n\n$$E\\left[g(X)\\right] = \\int_{\\mathcal{S}} g(x) f(x) dx$$\n\nfor continuous random variables and\n\n$$E\\left[g(X)\\right] = \\sum_{\\mathcal{S}} g(x) f(x)$$\n\nfor discrete random variables.\n\nExpected Value (Mean) (@def-mean) \n: Let $X$ be a random variable with density function $f$ defined over the support $\\mathcal{S}$.  The expected value of a random variable, also called the mean and denoted $E(X)$, is given by\n\n$$E(X) = \\int_{\\mathcal{S}} x f(x) dx$$\n\nfor continuous random variables and \n\n$$E(X) = \\sum_{\\mathcal{S}} x f(x)$$\n\nfor discrete random variables.\n\nExtrapolation (@def-extrapolation) \n: Extrapolation occurs when we use a model to predict outside of the region for which data is available.\n\nFrequency (@def-frequency) \n: The number of observations in a sample falling into a particular group (level) defined by a categorical variable.\n\nFrequentist Interpretation of Probability (@def-frequentist-interpretation) \n: In this perspective, the probability of $A$ describes the long-run behavior of the event.  Specifically, consider repeating the random process $m$ times, and let $f(A)$ represent the number of times the event $A$ occurs out of those $m$ replications.  Then,\n\n$$Pr(A) = \\lim_{m \\rightarrow \\infty} \\frac{f(A)}{m}.$$\n\nGeneral Mixture Distribution (@def-general-mixture-distribution) \n: Let $\\theta$ be a parameter with support $\\Theta$, and let $\\pi_k(\\theta)$ be a valid distribution on the support, for $k = 1, 2, \\dotsc, K$.  Then,\n\n$$\\pi(\\theta) = \\sum_{k=1}^{K} w_k \\pi_k(\\theta)$$\n\nis a valid prior distribution provided $\\sum_{k=1}^{K} w_k = 1$.\n\nHighest Density Interval (@def-hdi) \n: The highest density interval, often called an HDI or HPD (for highest posterior density), chooses the endpoints such that the interval is as short as possible.\n\nWhen the density is unimodal, this can be accomplished by choosing the endpoints $a$ and $b$ such that\n    \n$$\\pi(\\theta \\mid \\bm{y}) \\mid_{\\theta = a} = \\pi(\\theta \\mid \\bm{y}) \\mid_{\\theta = b}$$\n\nand \n\n$$\\int_{a}^{b} \\pi(\\theta \\mid \\bm{y} d\\theta = c.$$\n\nHistogram Approach to Constructing a Prior (@def-histogram-prior) \n: Using expert information, attach probability to various intervals for the parameter.  Specifically,\n\n  - Define $m$ intervals $\\left(\\theta_{j-1}, \\theta_j\\right)$ for $j = 1, 2, \\dotsc, m$ that partition the parameter space; define $\\theta_0$ as the lower bound of the support for the parameter, and define $\\theta_m$ as the upper bound of the support for the parameter.\n  - Eliciting expert opinions, assign probability $\\pi_j$ to each interval: $\\pi_j = Pr\\left(\\theta_{j-1} < \\theta < \\theta_j\\right)$ for each $j = 1, 2, \\dotsc, m$.\n  - Set the prior $\\pi(\\theta)$ to be the piecewise distribution over this interval where $\\sum_{j=1}^{m} \\pi_j = 1$.\n\nHyperparameter (@def-hyperparameter) \n: A constant term of a prior distribution that characterizes the family we are considering.\n\nHypothesis Testing (@def-hypothesis-testing) \n: Using a sample to determine if the data is consistent with a working theory or if there is evidence to suggest the data is not consistent with the theory.\n\nIdentically Distributed (@def-identically-distributed) \n: We say that random variables $X$ and $Y$ are identically distributed if $F_X(u) = F_Y(u)$ for all $u$.  This is equivalent to saying the two random variables have the same density function $f$.\n\nIndependence (@def-independence) \n: Random variables $X_1, X_2, \\dotsc, X_n$ are said to be mutually independent (or just \"independent\") if and only if\n\n$$Pr\\left(X_1 \\in A_1, X_2 \\in A_2, \\dotsb, X_n \\in A_n\\right) = \\prod_{i=1}^{n} Pr\\left(X_i \\in A_i\\right),$$\n\nwhere $A_1, A_2, \\dotsc, A_n$ are arbitrary sets.  Perhaps more helpful, $X_1, X_2, \\dotsc, X_n$ are said to be mutually independent if and only if\n\n$$f_{\\bm{X}}(\\bm{x}) = \\prod_{i=1}^{n} f_{X_i}\\left(x_i\\right).$$\n\nIndicator Variable (@def-indicator-variable) \n: An indicator variable is a binary variable (takes on the value 0 or 1), taking the value 1 when a specific event occurs.  A collection of $k-1$ indicator variables can be used to capture a categorical variable with $k$ levels in a regression model.\n\n  - The \"reference group\" (or reference level) is the group (level) defined by setting all indicator variables in a regression model to 0.\n\nInterquartile Range (@def-interquartile-range) \n: Often abbreviated as IQR, this is the distance between the first and third quartiles.  This measure of spread indicates the range over which the middle 50% of the data is spread.\n\nInterval Estimation (@def-interval-estimation) \n: Interval estimation is the process of estimating a parameter with a range of values.  This is like trying to capture a target with a ring.\n\nJoint Density (@def-joint-density) \n: For a random vector $\\bm{X}$, the function $f_{\\bm{X}}(\\bm{x})$ such that for any set $A \\in \\mathbb{R}^n$, we have\n\n$$Pr(\\bm{X} \\in A) = \\int \\dotsi \\int_{A} f_{\\bm{X}}(\\bm{x}) dx_1 \\dotsb dx_n$$\n\nis called the joint density function; this is also referred to as the _likelihood_.  Integrals are replaced by sums when appropriate.\n\nKernel of a Distribution (@def-kernel) \n: Let $k(x)$ be a non-negative function of $x$ over some region $\\mathcal{S}_X$.  Then, a valid density function $f$ over the support $\\mathcal{S}_X$ can be constructed by taking\n\n$$f(x) = a k(x)$$\n\nwhere $a > 0$ is a suitably chosen scaling constant to ensure the density integrates (or sums) to 1 over the support.  The function $k$ is known as the kernel of the distribution, and it can be used to identify the distributional family for a random variable.\n\nLaplace Prior (@def-laplace-prior) \n: The Laplace prior, also known as a \"flat\" prior, considers the form\n\n$$\\pi(\\theta) = 1 \\qquad \\forall \\theta \\in \\Theta.$$\n\nLink Function (@def-link-function) \n: The functional form \"linking\" the linear predictor \n\n$$\\beta_0 + \\sum_{j=1}^{p} \\beta_j (\\text{Predictor } j)_i$$\n\nto the mean response of the model in a regression model.  In particular, it is the function $g$ such that\n\n$$g\\left(\\theta_i\\right) = \\beta_0 + \\sum_{j=1}^{p} \\beta_j (\\text{Predictor } j)_i.$$\n\nCommon link functions include:\n  \n  - Identity link: $g\\left(\\theta_i\\right) = \\theta_i$\n  - Logit link: $g\\left(\\theta_i\\right) = \\log\\left(\\frac{\\theta_i}{1 - \\theta_i}\\right)$\n  - Log link: $g\\left(\\theta_i\\right) = \\log\\left(\\theta_i\\right)$\n  - Inverse link: $g\\left(\\theta_i\\right) = \\frac{1}{\\theta_i}$\n  - Negative inverse link: $g\\left(\\theta_i\\right) = -\\frac{1}{\\theta_i}$\n  - Inverse squared link: $g\\left(\\theta_i\\right) = \\frac{1}{\\theta_i^2}$\n\nLogistic Regression (@def-logistic-regression) \n: Given a binary response; logistic regression assumes that\n\n$$\n\\begin{aligned}\n  (\\text{Response})_i &\\mid (\\text{Predictors})_i, \\bs{\\beta} \\ind Ber\\left(\\theta_i\\right) \\\\\n  \\theta_i &= \\frac{e^{\\beta_0 + \\sum_{j=1}^{p} \\beta_j (\\text{Predictor } j)_i}}{1 + e^{\\beta_0 + \\sum_{j=1}^{p} \\beta_j (\\text{Predictor } j)_i}}.\n\\end{aligned}\n$$\n\nMarginal Density (@def-marginal-density) \n: For a random vector $\\bm{X}$, the marginal density of the first component $X_1$ (without loss of generality) is\n\n$$f_{X_1}(u) = \\int \\dotsi \\int f_{\\bm{X}}(\\bm{x}) dx_2 \\dotsb dx_n.$$\n\nMarkov Chain (@def-markov-chain) \n: A sequence of random vectors $\\theta^{(0)}, \\theta^{(1)}, \\theta^{(2)}, \\dotsc, \\theta^{(n)}$ is a Markov Chain with stationary transition probabilities if for any set $A$ and any $k \\leq n$\n\n$$\n\\begin{aligned}\n  Pr\\left(\\theta^{(k)} \\in A \\mid \\theta^{(1)}, \\theta^{(2)}, \\dotsc, \\theta^{(k-1)}\\right)\n    &= Pr\\left(\\theta^{(k)} \\in A \\mid \\theta^{(k-1)}\\right) \\\\\n    &= \\int_{A} q\\left(\\theta^{(k)} \\mid \\theta^{(k-1)}\\right) d\\theta^{(k)}\n\\end{aligned}\n$$\n\nwhere $q$ is called the transition kernel.\n\nMethod of Distribution Functions (@def-method-of-distribution-functions) \n: Let $X$ be a continuous random variable with density $f$ and cumulative distribution function $F$.  Consider $Y = h(X)$.  The following process provides the density function $g$ of $Y$ by first finding its cumulative distribution function $G$.\n\n  1. Find the set $A$ for which $h(X) \\leq t$ if and only if $X \\in A$.\n  2. Recognize that $G(y) = Pr(Y \\leq y) = Pr\\left(h(X) \\leq y\\right) = Pr(X \\in A)$.\n  3. If interested in $g(y)$, note that $g(y) = \\frac{\\partial}{\\partial y} G(y)$.\n\nMetropolis Algorithm (@def-metropolis-algorithm) \n: Suppose we want to generate random variates from the density $\\pi(\\theta \\mid \\bm{y})$.  We perform the following steps:\n\n  1. Generate an initial value $\\theta^{(0)}$.  \n  2. At the $k$-th step, generate $\\theta^*$ (a candidate) according to a symmetric proposal density $q\\left(\\theta \\mid \\theta^{(k-1)}\\right)$.  \n  3. Compute $A\\left(\\theta^*, \\theta^{(k-1)}\\right)$ where\n    $$A\\left(\\theta^*, \\theta^{(k-1)}\\right) = \\frac{\\pi\\left(\\theta^* \\mid \\bm{y}\\right)}{\\pi\\left(\\theta^{(k-1)} \\mid \\bm{y}\\right)} = \\frac{f\\left(\\bm{y} \\mid \\theta^*\\right) \\pi\\left(\\theta^*\\right)}{f\\left(\\bm{y} \\mid \\theta^{(k-1)}\\right) \\pi\\left(\\theta^{(k-1)}\\right)}.$$\n  4. Generate $U \\sim Unif(0,1)$.  If $U \\leq A\\left(\\theta^*, \\theta^{(k-1)}\\right)$, then set $\\theta^{(k)} = \\theta^*$; else, set $\\theta^{(k)} = \\theta^{(k-1)}$.\n  5. Repeat Steps 2-4 $m$ times, for some large $m$.\n\nWhen generating an initial value, $\\theta^{(0)}$, we could choose $\\theta^{(0)} \\sim \\pi(\\theta)$ if the prior is easy to generate from.  While it is common to choose $q(\\cdot)$ to be a Normal distribution with mean $\\theta^{(k-1)}$, it is not a requirement to do so; when a Normal distribution is used, it can be difficult to determine a reasonable variance (too large, and you drift too far away; too small, and you do not move at all).\n\nMixture Distribution (@def-mixture-distribution) \n: Let $X$ be a random variable and $f(x)$ and $g(x)$ be valid density functions defined on a common support.  Then, \n\n$$h(x) = wf(x) + (1 - w) g(x),$$\n\nwhere $0 < w < 1$, is known as a mixture distribution.\n\nMonte Carlo Error (@def-mc-error) \n: Also called the standard error for an approximation of the form $m^{-1} \\sum\\limits_{k=1}^{m} g\\left(X_k\\right)$, the MC error is given by\n    \n$$\\sqrt{\\frac{1}{m(m-1)} \\sum_{k=1}^{m} \\left[g\\left(X_k\\right) - \\frac{1}{m} \\sum_{j=1}^{m} g\\left(X_j\\right)\\right]^2}$$\n\nwhich is the sample standard deviation of the generated variates divided by the square root of the number of replications.\n\nMonte Carlo Integration (@def-mc-integration) \n: Consider an integral of the form\n\n$$\\int_{\\mathcal{S}} g(x) f(x) dx$$\n\nwhere $f(x)$ is a valid density function for a random variable $X$ with support $\\mathcal{S}$.  Then, the following algorithm, known as Monte Carlo (or MC) Integration, gives a numerical approximation to the integral:\n\n  1. Take a random sample $X_1, X_2, \\dotsc, X_m$ such that $X_i \\sim f(x)$ for all $i$, where $m$ is large.\n  2. Compute $m^{-1} \\sum_{i=1}^{m} g\\left(X_i\\right)$.\n  \nBy the Law of Large Numbers,\n\n$$\\frac{1}{m} \\sum_{i=1}^{m} g\\left(X_i\\right) \\approx \\int_{\\mathcal{S}} g(x) f(x) dx.$$\n\nNoninformative Prior (@def-noninformative-prior) \n: A prior distribution which is derived solely based on the form of the likelihood.\n\nNull Hypothesis (@def-null-hypothesis) \n: The statement (or theory) about the parameter that we would like to _disprove_.  This is denoted $H_0$, read \"H-naught\" or \"H-zero\".\n\nNull Value (@def-null-value) \n: The value associated with the equality component of the null hypothesis; it forms the threshold or boundary between the hypotheses.  Note: not all questions of interest require a null value be specified.\n\nNumeric Variable (@def-numeric) \n: Also called a \"quantitative variable,\" a measurement on a subject which takes on a numeric value _and_ for which ordinary arithmetic makes sense.\n\nObservational Study (@def-observational-study) \n: A study in which each subject \"self-selects\" into one of groups being compared in the study.  The phrase \"self-selects\" is used very loosely here and can include studies for which the groups are defined by an inherent characteristic or are chosen haphazardly.\n\nOutlier (@def-outlier) \n: An individual observation which is so extreme, relative to the rest of the observations in the sample, that it does not appear to conform to the same distribution.\n\nParameter (@def-parameter) \n: Numeric quantity which summarizes the distribution of a variable within the _population_ of interest.  Generally denoted by Greek letters in statistical formulas.\n\nPercentile (@def-percentile) \n: The $k$-th percentile is the value $q$ such that $k$% of the values in the distribution are less than or equal to $q$.  For example,\n\n  - 25% of values in a distribution are less than or equal to the 25-th percentile (known as the \"first quartile\" and denoted $Q_1$).\n  - 50% of values in a distribution are less than or equal to the 50-th percentile (known as the \"median\").\n  - 75% of values in a distribution are less than or equal to the 75-th percentile (known as the \"third quartile\" and denoted $Q_3$).\n\nPercentile for a Random Variable (@def-population-percentile) \n: Let $X$ be a random variable with density function $f$.  The $100k$ percentile is the value $q$ such that\n\n$$Pr(X \\leq q) = k.$$\n\nPoint Estimation (@def-point-estimation) \n: Point estimation is the process of estimating a parameter with a single statistic.  This is like trying to hit an infinitesimally small target with a dart.\n\nPopulation (@def-population) \n: The collection of subjects we would like to say something about.\n\nPosterior Distribution (@def-posterior-distribution) \n: A distribution quantifying our beliefs about the uncertainty in the parameter(s) of the underlying sampling distribution _after_ observing data.  This is often denoted by $\\pi(\\bs{\\theta} \\mid \\bm{y})$ where $\\bs{\\theta}$ is the parameter vector and $\\bm{y}$ the observe data.  \n\nGiven the likelihood $f(\\bm{y} \\mid \\bs{\\theta})$ and a prior distribution on the parameters $\\pi(\\bs{\\theta})$, the posterior distribution is computed using Bayes Theorem:\n\n$$\\pi(\\bs{\\theta} \\mid \\bm{y}) = \\frac{f(\\bm{y} \\mid \\bs{\\theta}) \\pi(\\theta)}{\\int f(\\bm{y} \\mid \\bs{\\theta}) \\pi(\\bs{\\theta}) d\\bs{\\theta}}.$$\n\nPosterior Mean (@def-posterior-mean) \n: The posterior mean is the average value of the parameter, given the data:\n\n$$E\\left[\\bs{\\theta} \\mid \\bm{y}\\right] = \\int \\bs{\\theta} \\pi(\\theta \\mid \\bm{y}) d\\bs{\\theta}.$$\n\nPosterior Median (@def-posterior-median) \n: We are 50% sure, given the data, the parameter falls below the posterior median.  Formally, the posterior median is the value $q$ such that\n\n$$0.5 = \\int_{-\\infty}^{q} \\pi(\\theta \\mid \\bm{y}) d\\theta.$$\n\nPosterior Mode (@def-posterior-mode) \n: We think of the posterior mode as the most likely value of the parameter, given the data.  If the posterior distribution is continuous, the posterior mode is the value of the parameter that maximizes the posterior distribution.  Formally, the posterior mode is given by\n\n$$\\arg \\max_{\\theta} \\pi(\\theta \\mid \\bm{y}).$$\n\nPosterior Odds (@def-posterior-odds) \n: Let $H_j$ denote the hypothesis that $\\theta \\in \\Theta_j$ for some region $\\Theta_j$.  Then, the posterior odds _in favor of_ $H_j$ is given by\n\n$$\\frac{Pr\\left(\\theta \\in \\Theta_j \\mid \\bm{y}\\right)}{Pr\\left(\\theta \\notin \\Theta_j \\mid \\bm{y}\\right)}.$$\n\nPosterior Predictive Distribution (@def-posterior-predictive-distribution) \n: Let $\\bm{Y}^*$ represent a collection of $m$ _future_ observations.  The distribution of these future observations given the observed data $\\bm{Y}$ (of length $n$), called the posterior predictive distribution, is given by\n\n$$\\pi\\left(\\bm{y}^* \\mid \\bm{y}\\right) = \\int f\\left(\\bm{y}^* \\mid \\theta\\right) \\pi(\\theta \\mid \\bm{y}) d\\theta.$$\n\nPotential (@def-potential) \n: The potential of a value $\\theta$ is the negative logarithm of the posterior evaluated at $\\theta$.  In practice, we need only know the potential up to a constant.  That is, it suffices to define the potential as\n\n$$\\text{Potential}(\\theta) = -\\log\\left[f(\\bm{y} \\mid \\theta) \\pi(\\theta)\\right].$$\n\nPrior Distribution (@def-prior-distribution) \n: A distribution quantifying our beliefs about uncertainty in the _parameter(s)_ of the underlying sampling distribution _prior to_ observing any data.  This is often denoted by $\\pi(\\bs{\\theta})$ where $\\bs{\\theta}$ is the parameter vector.\n\n  - This relies on a _subjective_ view of probability.\n  - As prior beliefs are subjective, there is no \"one\" prior, but each individual may have a unique prior.\n\nPrior Predictive Distribution (@def-prior-predictive-distribution) \n: The prior predictive distribution is the marginal distribution of the response(s) prior to observing any data:\n\n$$m(\\bm{y}) = \\int f(\\bm{y} \\mid \\theta) \\pi(\\theta) d\\theta.$$\n\nThe distribution marginalizes the parameter out of the likelihood using the beliefs from the prior distribution.\n\nRandom Sample (@def-random-sample) \n: A random sample of size $n$ refers to a collection of $n$ random variables $X_1, X_2, \\dotsc, X_n$ such that the random variables are mutually independent, and the distribution of each random variable is identical.\n\nRandom Variable (@def-random-variable) \n: Let $\\mathcal{S}$ be the sample space corresponding to a random process; a random variable $X$ is a function mapping elements of the sample space to the real line.\n\nRandom variables represent a measurement that will be collected during the course of a study.  Random variables are typically represented by a capital letter.\n\nRandom Vector (@def-random-vector) \n: Let $X_1, X_2, \\dots, X_n$ be $n$ random variables.  Then, the vector $\\bm{X} = \\left(X_1, X_2, \\dots, X_n\\right)^\\top$ is a random vector of length $n$.\n\nRandomization (@def-randomization) \n: Randomization can refer to random _selection_ or random _allocation_.  Random selection refers to the use of a random mechanism (e.g., a simple random sample, @def-simple-random-sample, or a stratified random sample, @def-stratified-random-sample) to select units from the population.  Random selection minimizes bias.\n\nRandom allocation refers to the use of a random mechanism when assigning units to a specific treatment group in a controlled experiment (@def-controlled-experiment).  Random allocation eliminates confounding and permits causal interpretations.\n\nReduction of Noise (@def-noise-reduction) \n: Reducing extraneous sources of variability can be accomplished by fixing extraneous variables or blocking (@def-blocking).  These actions reduce the number of differences between the units under study.\n\nRegression (@def-regression) \n: A regression model is one for which the parameter(s) governing the data generating process depends on one or more predictors.  \"Parametric\" regression models do this through specifying a functional form for the dependence of the parameter(s) on the predictor(s).\n\nRelative Frequency (@def-relative-frequency) \n: Also called the \"proportion,\" the fraction of observations falling into a particular group (level) of a categorical variable.\n\nReplication (@def-replication) \n: Replication results from taking measurements on different units (or subjects), for which you expect the results to be similar.  That is, any variability across the units is due to natural variability within the population.\n\nResidual (@def-residual) \n: A residual is the difference between an observed response and the predicted mean response for that same individual:\n\n$$(\\text{Residual})_i = (\\text{Response})_i - (\\text{Fitted Value})_i,$$\n\nwhere \n\n$$(\\text{Fitted Value})_i = \\widehat{\\beta}_0 + \\sum_{j=1}^{p} \\widehat{\\beta}_j (\\text{Predictor} j)_i.$$\n\nResponse (@def-response) \n: The primary variable of interest within a study.  This is the variable you would either like to explain or estimate.\n\nSample (@def-sample) \n: The collection of subjects for which we actually obtain measurements (data).\n\nSample Space (@def-sample-space) \n: The sample space for a random process is the collection of all possible results that we might observe.\n\nSimple Random Sample (@def-simple-random-sample) \n: Often abbreviated SRS, this is a sample of size $n$ such that _every_ collection of size $n$ is equally likely to be the resulting sample.  This is equivalent to a lottery.\n\nStandard Deviation (@def-standard-deviation) \n: A measure of spread, this is the square root of the variance.\n\nStationary Distribution (@def-stationary-distribution) \n: Let $\\theta^{(0)}, \\theta^{(1)}, \\theta^{(2)}, \\dotsc, \\theta^{(n)}$ be a Markov Chain.  The stationary distribution of the Markov Chain is the distribution $p(\\theta)$ such that\n    \n$$Pr\\left(\\theta^{(k)} \\in A\\right) = \\int_{A} p(\\theta) d\\theta.$$\n\nStatistic (@def-statistic) \n: Numeric quantity which summarizes the distribution of a variable within a _sample_.\n\nStatistical Inference (@def-inference) \n: The process of using a sample to characterize some aspect of the underlying population.\n\nStratified Random Sample (@def-stratified-random-sample) \n: A sample in which the population is first divided into groups, or strata, based on a characteristic of interest; a simple random sample is then taken within each group.\n\nSubjective Interpretation of Probability (@def-subjective-interpretation) \n: In this perspective, the probability of $A$ describes the individual's uncertainty about event $A$.\n\nSupport (@def-support) \n: The support of a random variable is the set of all possible values the random variable can take.\n\nVariability (@def-variability) \n: The notion that measurements differ from one observation to another.\n\nVariable (@def-variable) \n: A measurement, or category, describing some aspect of the subject.\n\nVariance (@def-variance) \n: Let $X$ be a random variable with density function $f$ defined over the support $\\mathcal{S}$.  The variance of a random variable, denoted $Var(X)$, is given by\n\n$$Var(X) = E\\left[X - E(X)\\right]^2 = E\\left(X^2\\right) - E^2(X).$$\n\nIf we let $\\mu = E(X)$, then this is equivalent to\n\n$$\\int_{\\mathcal{S}} (x - \\mu)^2 f(x) dx$$\n\nfor continuous random variables and \n\n$$\\sum_{\\mathcal{S}} (x - \\mu)^2 f(x)$$\n\nfor discrete random variables.\n\nVariance (@def-variance) \n: A measure of spread, this roughly captures the average distance values in the distribution are from the mean.\n\nFor a sample of size $n$, it is computed by\n$$s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} \\left(x_i - \\bar{x}\\right)^2$$\n\nwhere $\\bar{x}$ is the sample mean and $x_i$ is the $i$-th value in the sample.  The division by $n-1$ instead of $n$ removes bias in the statistic.\n\nThe symbol $\\sigma^2$ is often used to denote the variance in the population.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}