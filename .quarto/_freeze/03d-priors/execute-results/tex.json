{
  "hash": "4f8df02ec19c344f303ad78557d9e1f1",
  "result": {
    "markdown": "# Quantifying/Modeling Prior Information {#sec-priors}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\providecommand{\\norm}[1]{\\lVert#1\\rVert}\n\\providecommand{\\abs}[1]{\\lvert#1\\rvert}\n\\providecommand{\\iid}{\\stackrel{\\text{IID}}{\\sim}}\n\\providecommand{\\ind}{\\stackrel{\\text{Ind}}{\\sim}}\n  \n\\providecommand{\\bm}[1]{\\mathbf{#1}}\n\\providecommand{\\bs}[1]{\\boldsymbol{#1}}\n\\providecommand{\\bbeta}{\\bs{\\beta}}\n  \n\\providecommand{\\Ell}{\\mathcal{L}}\n\\providecommand{\\indep}{\\perp\\negthickspace\\negmedspace\\perp}\n\n\n\nData contributes information to, and therefore impacts, our beliefs. But, prior to beginning a study, we generally have some established beliefs --- based on previous studies, expert opinions, personal experience, etc. The Bayesian framework explicitly incorporates these established _prior_ beliefs in the analysis. The beliefs just need to be quantified.\n\n:::{.callout-tip}\n## Big Idea\nThe Bayesian framework encodes any uncertainty through probability distributions.\n:::\n\nBefore we examine the technical aspects of quantifying the beliefs we have prior to the start of a study, we need to consider how this fits into the larger scope of performing inference.  Recall that our primary aim is to make some statement about the population using a corresponding sample.  Further, we have some model for the data generating process up to some unknown parameters (this was the focus of the previous chapter).  When we collect data, it provides additional information about these unknown parameters.  That is, the data impacts the beliefs we have about these unknown parameters.  Similarly, any beliefs we have entering the study must relate to these unknown parameters.\n\nPrior to beginning the study, we generally have some notion about the parameters that govern the data generating process. What is a typical GPA for a college student? How much does a member of the mathematics faculty earn each year, on average? While we use data to inform these beliefs (topic of the next chapter), even without data available, we have some idea of where we think the answer lies. Bayesians encode these beliefs into probability distributions. The beliefs we have prior to seeing the data are described by a \"prior\" distribution, since the beliefs were those we had _a priori_.\n\n:::{#def-prior-distribution}\n## Prior Distribution\nA distribution quantifying our beliefs about uncertainty in the _parameter(s)_ of the underlying sampling distribution _prior to_ observing any data.  This is often denoted by $\\pi(\\bs{\\theta})$ where $\\bs{\\theta}$ is the parameter vector.\n\n  - This relies on a _subjective_ view of probability.\n  - As prior beliefs are subjective, there is no \"one\" prior, but each individual may have a unique prior.\n:::\n\nConstructing a prior distribution is not all that different from constructing the likelihood. There are several aspects involved, but it is all about understanding the structure of the beliefs.\n\n:::{.callout-note}\n## Tips for Constructing a Prior\nThe following considerations should be kept in mind when constructing the prior distribution.\n\n  - Identify the unknown parameter(s).  That is, on what unknown value(s) does the _likelihood_ (model for the data generating process) depend?\n  - Describe the support for the parameter(s).\n  - Use clear statements about our beliefs of the parameters to determine the __hyperparameters__.\n:::\n\n:::{#def-hyperparameter}\n## Hyperparameter\nA constant term of a prior distribution that characterizes the family we are considering.  \n:::\n\n:::{.callout-note}\nIt is sometimes said that a hyperparameter is a \"parameter\" of the prior distribution.  You want to distinguish between \"parameters\" (constant terms that characterize the likelihood), which are unknown, and hyperparameters (constant terms that characterize a prior), which are known values chosen such that the prior distribution reflects our prior beliefs.\n:::\n\n\n:::{#exm-naive}\n## A Naive Classification of College Students\nRose-Hulman Institute of Technology (RHIT) and Indiana State University (ISU) are located in Terre Haute, IN.  While both colleges cater to undergraduate students, they have different profiles.  For the 2021-2022 academic year, [Indiana State University reported](https://irt2.indstate.edu/cms7/ir/assets/File/CDS22.pdf) having 5738 full-time undergraduate students, 3232 (56.3%) of which identified as female.  For the same year, [Rose-Hulman reported](https://www.rose-hulman.edu/academics/academic-affairs/irpa/reports/CDS_AY_2021-22.pdf) having 2058 full-time undergraduate students, 507 (24.6%) of which identified as female.\n\nSuppose an individual sees a group of 10 college students hanging out at a coffee shop in Terre Haute; they are interested in determining which college the students attend.  If the students attend ISU, then we would expect 56.3% to identify as female; if the students attend RHIT, then we would expect 24.6% to identify as female.  However, since the coffee shop is located in downtown Terre Haute (which is near the ISU campus), the individual believes there is a 60% chance the students are from ISU.\n:::\n\nNotice that in this example, no data has been collected --- we have no information on how the students within the group identify.  The belief about how likely the students are to attend ISU is stated _prior_ to seeing any data, and this belief can therefore be used to form a prior distribution.  Again, notice the use of \"a\" when describing the prior instead of \"the.\"  While this prior will reflect the beliefs of this particular individual, if someone had a different set of beliefs, we would arrive at a different prior.\n\nLet $Y$ represent the number of students who identify as female.  Then, $Y \\sim Bin(10, \\theta)$, where $\\theta$ is the probability that a student identifies as female.  Notice we are modeling the data that we have not yet collected; that is, this represents the probability model for the likelihood.  This likelihood depends on the unknown parameter $\\theta$, which represents the probability a randomly selected student identifies as female.  This is the first step in constructing a prior --- constructing the likelihood and identifying any unknown parameters.\n\nNow, we describe the support for $\\theta$.  Ordinarily, we might think that $\\theta$ could be any value between 0 and 1 since it represents a probability.  However, notice that the context we have here suggests there are really only two possible values: either $\\theta = 0.563$, representing the gender diversity of ISU students; or $\\theta = 0.246$ representing the gender diversity of RHIT students.  Therefore, the support of $\\theta$ in this particular context is the set $\\{0.563, 0.246\\}$.  Since the support is countable, we will need a discrete distribution for $\\theta$.  \n\nWe are now ready to write a distribution that captures the individual's beliefs prior to observing the data.  In this example, the individual is 60% sure the students are from ISU; we write this as\n\n$$\nPr(\\theta = u) = \\begin{cases}\n  0.4 & u = 0.246 \\\\\n  0.6 & u = 0.563. \\end{cases}\n$$ {#eq-naive-prior-1}\n\nThis says the individual is 60% sure that $\\theta$ takes the value 0.563, and they are 40% sure that $\\theta$ takes the value 0.246; the 0.6 is the _hyperparameter_ that governs this distribution.  It was chosen to correspond with the prior beliefs stated by the individual.\n\nThis is a completely acceptable way of writing the prior distribution.  However, as we will later see, the prior distribution is much easier to work with when written in a compact form instead of piecewise notation.  For example, we can rewrite @eq-naive-prior-1 as\n\n$$\\pi(\\theta) = 0.4\\delta(\\theta - 0.246) + 0.6\\delta(\\theta - 0.563)$$ {#eq-naive-prior}\n\nwhere $\\delta(x)$ is the Dirac delta function.\n\n:::{#def-dirac-delta}\n## Dirac Delta Function\nThe Dirac delta function is the function (not in a rigorous sense) $\\delta$ such that\n\n$$\\int_{-\\infty}^{\\infty} \\delta(x) dx = 1$$\n\nand\n\n$$\\int_{-\\infty}^{\\infty} f(x) \\delta(x) dx = f(0)$$\n\nfor any real-valued function $f$.  \n\nThe Dirac delta function allows us to describe a discrete distribution, which places mass at a single point, as a continuous function on the real line.\n:::\n\nThe above example offers a rather simplistic view of constructing a prior.  In practice, nearly every problem will involve some numerical computation at some point. Rarely, perhaps never, are we simply provided with a complete prior distribution and asked to perform an analysis. Generally, we must convert statements from researchers into some type of distribution.\n\n:::{#exm-csec-prior}\n## C-Section Deliveries Continued\n@exm-csec introduced a study, a component of which includes estimating the probability of a mother undergoing a C-section delivery at a particular hospital.\n\nWhile we do not know the probability of a C-section, we do have some external information (even before collecting data).  Specifically, the [March of Dimes](https://www.marchofdimes.org/peristats/data?reg=99&top=8&stop=87&lev=1&slev=4&obj=18&sreg=18) has reported that in 2021, 30.4% of live births in Indiana were C-section deliveries.  Suppose we have the following beliefs:\n\n  - On average, the rate of C-sections at Union Hospital equals the rate of C-sections in the state of Indiana.\n  - We feel fairly confident (90% sure) the rate of C-sections at Union Hospital is between 20% and 40%.\n  \nDevelop a suitable prior distribution which captures these beliefs.\n:::\n\n:::{.solution}\nAs is typical, the prior beliefs that have been provided to us are limited; that is, they do not come pre-packaged in the form of a prior distribution.  So, we must develop a prior distribution that aligns with these beliefs.  Let's begin by converting the above beliefs into statements about the unknown parameter.\n\nThe first belief specifies the average value of the parameter; specifically,\n\n$$E(\\theta) = 0.304.$$\n\nThe second belief conveys information about where the parameter is located; specifically,\n\n$$Pr(0.2 < \\theta < 0.4) = \\int_{0.2}^{0.4} \\pi(\\theta) d\\theta = 0.9.$$\n\nNotice the use of the subjective interpretation of probability in capturing this belief.  Unfortunately, these two statements alone do not define a unique distribution; this is extremely common as discipline experts do not typically think in probability distributions.  Therefore, there is no one unique prior distribution (even for this set of beliefs); instead, we must make some decisions.\n\nNotice that the unknown parameter $\\theta$ is a probability; therefore, we know that $\\pi(\\theta)$ must have a support on the interval $(0, 1)$ since those are the only possible values for $\\theta$.  Without further guidance, it seems reasonable to select a common distributional family that shares this support; we suggest the Beta distribution.  Therefore, we suggest that $\\theta \\sim Beta(a, b)$.  We now must select the values of the hyperparameters $a$ and $b$ so that the prior distribution captures the above statements.  That is, we want to choose the hyperparameters to satisfy the following system of equations:\n\n$$\n\\begin{aligned}\n  0.304 &= E(\\theta) = \\frac{a}{a+b} \\\\\n  0.90 &= \\int_{0.2}^{0.4} \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} \\theta^{a-1} (1 - \\theta)^{b-1} d\\theta.\n\\end{aligned}\n$$\n\n\n\n::: {.cell}\n\n:::\n\n\n\nAs we have two equations and two unknowns, this system can be solved (numerically).  Solving this system results in $a = 17$ and $b = 39$ (approximately). Note that the choice of hyperparameters need not carry a lot of precision; these values get us extremely close to the prior beliefs.  Therefore, we propose representing our prior beliefs with the prior distribution\n\n$$\\pi(\\theta) = \\frac{\\Gamma(17 + 39)}{\\Gamma(17)\\Gamma(39)} \\theta^{17-1} (1 - \\theta)^{39-1}$$ {#eq-csec-prior}\n\nor equivalently $\\theta \\sim Beta(17, 39)$.\n:::\n\n:::{.callout-tip}\n## Big Idea\nA prior distribution quantifies the uncertainty we have about a parameter prior to observing data.\n:::",
    "supporting": [
      "03d-priors_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}