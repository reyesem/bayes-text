# Assessment for Regression Models for the Mean {#sec-reg-conditions}

{{< include _setupcode.qmd >}}

While we have tried to emphasize the flexibility of regression models, the most common regression model is one of the form

$$
  \begin{aligned}
    (\text{Response})_i 
      &\mid (\text{Predictors})_i, \bs{\beta}, \bs{\theta} \ind f\left(\mu_i,\bs{\theta}\right) \\
    \mu_i &= \beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor } j)_i,
  \end{aligned}
$$ {#eq-reg-meanmodel}

where $\mu_i$ represents the (conditional) mean response and $\bs{\theta}$ captures additional parameters that do not depend on the predictors (often scale parameters).  @eq-reg-meanmodel represents a model focused on the mean response.

It is reasonable to ask if the model we have constructed is reasonable for the data we have observed.  When our models are of the form described in @eq-reg-meanmodel, a large assumption is that we have correctly specified the mean response.  This can be assessed graphically using _residuals_.

:::{#def-residual}
## Residual
A residual is the difference between an observed response and the predicted mean response for that same individual:

$$(\text{Residual})_i = (\text{Response})_i - (\text{Fitted Value})_i,$$

where 

$$(\text{Fitted Value})_i = \widehat{\beta}_0 + \sum_{j=1}^{p} \widehat{\beta}_j (\text{Predictor} j)_i.$$
:::

:::{.callout-note}
In a classical introductory statistics course, the least squares estimates are used when computing the residuals.  However, from the Bayesian framework, we have explored various point estimates.  It is common to use the posterior mean for each parameter when computing the residuals; however, nothing prohibits the use of the posterior median or another point estimate.  Transparency is critical; you should be clear about the analysis you have conducted.
:::

In order to assess that the form of the mean model is correctly specified, it is common to construct a graphic of the residuals against the fitted values.  If the form of the mean model is correct, there should not be any distinguishable pattern in the _location_ of the graphic.  Trends in the location suggest the form of the mean model is incorrectly specified (see @fig-residual-plot).

```{r}
#| label: fig-residual-plot
#| fig-cap: Plot of the residuals against the fitted values for two hypothetical models.  One illustrates what we would expect under a correctly specified mean model; the second is an example of a graphic indicating the mean model is misspecified.
#| fig-alt: Side by side scatter plots of residuals; the second graphic shows a trend in the location across the fitted values.
#| echo: false

set.seed(20220110)

fakedat <- tibble(
  case = rep(c('Mean Model\nCorrectly Specified',
               'Mean Model\nMisspecified'), each = 100),
  x = rep(runif(100), times = 2),
  error = rep(rnorm(100, sd = 0.05), times = 2),
  mean = case_when(
    case == 'Mean Model\nCorrectly Specified' ~ x,
    case == 'Mean Model\nMisspecified' ~ (x - 0.5)^2
  ),
  y = mean + error
) |>
  select(-error, -mean) |>
  nest(subset = c(x, y)) |>
  mutate(model = map(subset, ~ lm(y ~ x, data = .x)),
         diagnostics = map(model, ~ tibble(residuals = .x$residuals, 
                                           fitted = .x$fitted))) |>
  unnest(cols = diagnostics)

ggplot(data = fakedat,
       mapping = aes(y = residuals, x = fitted)) +
  geom_point() +
  geom_hline(yintercept = 0, color = 'blue', linetype = 2) +
  labs(y = 'Residuals', 
       x = 'Fitted Values') +
  facet_wrap(~ case, scales = 'free') +
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank())
```

:::{.callout-note}
## Assessing Specification of Mean Response
If the mean response is correctly specified, we would expect the residuals to balance around 0, regardless of the estimated mean response.  When examining a plot of the residuals against the fitted values, any trends in the location suggest the functional form of the mean response has been incorrectly specified.
:::

```{stan}
#| output.var: TextTherapy
#| echo: false
#| eval: false
data {
  int<lower = 0> N;
  real<lower = 0> times[N];
  real<lower = 0> age[N];
}
parameters {
  real<lower = 0, upper = 25> beta0;
  real<lower = 0, upper = 5> beta1;
}
model {
  for (i in 1:N) {
    target += -log(beta0 + beta1*age[i]) - (times[i] / (beta0 + beta1*age[i]));
  }
}

```


```{r}
#| echo: false
#| eval: false
saveRDS(TextTherapy, file = 'TextTherapy.rds')
```

```{r}
#| echo: false
#| eval: false
TextCsection <- readRDS('TextCsection.rds')
```


```{r}
#| echo: false
#| eval: false
dataList.therapy <- list(
  N = nrow(therapy.df),
  times = therapy.df$Recovery,
  age = therapy.df$Age
)

fit.therapy <- stan(model_code = TextTherapy@model_code,
                    data = dataList.therapy,
                    warmup = 2000,
                    iter = 5000,
                    chains = 3)

save(fit.therapy, file = 'TextTherapyFit.RData')
```

```{r}
#| echo: false
#| eval: true

load('TextTherapyFit.RData')
```



:::{#exm-therapy-mean0}
## Rehabilitation Therapy Continued
@exm-therapy described a study to investigate recovery time among patients who have undergone a corrective knee surgery.  Suppose we are willing to believe that the mean recovery time is linearly related to the age of a patient.  Combining the model for the likelihood suggested in @exm-therapy-likelihood and the advice on default priors specified in @sec-reg-priors, consider the following model:

$$
\begin{aligned}
  (\text{Recovery Time})_i &\mid (\text{Age})_i, \bs{\beta} \ind Exp\left(\theta_i\right) \\
  \theta_i &= \beta_0 + \beta_1 (\text{Age})_i \\
  \beta_0 &\sim Unif(0, 25) \\
  \beta_1 &\sim Unif(0, 5).
\end{aligned}
$$

This model was fit using an MCMC algorithm with 3 chains; a burn-in of 2000 was applied to each of the chains, and a total of 5000 samples were generated for each chain (for a total of 9000 variates after the burn-in period).  The posterior mean was used to estimate each of the unknown parameters.  @fig-mean0 presents the plot of the residuals against the fitted values for this model.  Comment on the assumption that the mean response is properly specified.
:::

```{r}
#| echo: false
#| eval: true
#| label: fig-mean0
#| fig-cap: Assessment of the mean response model for the Therapy example.
#| fig-alt: Scatter plot of residuals against the fitted values.

therapy.diag <- bind_cols(
  therapy.df,
  fit.therapy |>
    stan_to_df() |>
    summarise(
      beta0 = mean(beta0),
      beta1 = mean(beta1)
    )
) |>
  mutate(
    .fitted = beta0 + beta1 * Age,
    .resid = Recovery - .fitted
  )

ggplot(data = therapy.diag,
       mapping = aes(y = .resid, x = .fitted)) +
  geom_point() +
  labs(y = 'Residuals',
       x = 'Fitted Values\n(Using Posterior Mean)')
```

:::{.solution}
If the mean response model is correctly specified, we would expect the residuals to balance around 0 for all fitted values.  Notice that the residuals are centered below for the majority of the graphic, and only balance around 0 for large fitted values.  This trend in the location of the residuals suggests the mean response model was not correct specified.

In particular, this slight upward trend suggests that perhaps we were incorrect in forcing the intercept to be positive (remember, our prior distribution forced the support for the intercept to be positive).  We had done this because the mean response for an exponential distribution must always be positive.  However, because of extrapolation, forcing this to be the case at an age of 0 seems to be problematic.  There are two approaches we could consider in addressing this:

  - We could consider a different prior that allows the intercept to be negative, accepting that it is nonsensical and that the model will not predict well for small values of age.
  - We could center the age variable (by subtracting the average observed age from each observation).  Center the age variable does not impact the slope, but it changes the interpretation of the intercept.  In particular, the intercept would represent the average recovery time for a patient of average age.  This avoids the problem of extrapolation when interpreting the intercept and might address the problems we are seeing above.
:::

The other primary assumption that we make when fitting a regression model is that the conditional distribution of the response is appropriate.  In @exm-therapy-mean0, for example, we are assuming that the Exponential distribution for the response (conditional on the age) is appropriate, as opposed to a Normal distribution, for example.  One technique for assessing whether this distributional assumption is appropriate is to compare the posterior predictive distribution with the observed distribution.  As we have seen, the posterior predictive distribution (@def-posterior-predictive-distribution) can be challenging to derive; fortunately, it is easily simulated using a sample from the posterior distribution.  With the general model of @eq-reg-meanmodel in mind, we can generate the posterior predictive distribution as follows:

  - Obtain a sample of size $M$ from the posterior distribution of each unknown parameter: $\bs{\beta}^{(1)}, \bs{\beta}^{(2)}, \dotsc, \bs{\beta}^{(M)}$ and $\bs{\theta}^{(1)}, \bs{\theta}^{(2)}, \dotsc, \bs{\theta}^{(M)}$.
  - For each sample from the posterior, generate a new _sample_ of $n$ responses according to $(\text{Predicted Response})_i^{(m)} \sim f\left(\mu_i^{(m)}, \bs{\theta}^{(m)}\right)$ for $m = 1, 2, \dotsc, M$.  If we are conditioning on the predictors, they are taken to be those from the original sample.
  
The above two steps produces $M$ new samples; each generated sample will produce a unique distribution of the responses across the $n$ observations.  We can summarize each of these $M$ distributions using a density plot, overlaid on the same graphic.  Then, we can overlay the density from the observed response to get a sense of how they compare.  @fig-posterior-predictive-check gives an example of what this plot might look like.  

:::{.callout-note}
Due to the computational intensity of this graphic, it is common to do this for a random sample of variates instead of all $M$ variates generated by the MCMC algorithm.  
:::

:::{.callout-warning}
It is important to remember that comparing the posterior predictive distribution to that of the observed distribution is combining multiple conditions/assumptions together: the complete form of the distribution as well as how the individual observations vary compared to how the aggregate dataset varies.  While our modeling is conditioned, the density of the observed response marginalizes across the predictors.  Care must be taken not to over-interpret this graphic as proving we have the correct model.
:::

```{r}
#| label: fig-posterior-predictive-check
#| fig-cap: Two plots of the posterior predictive distributions from a regression model with the observed distribution.  One illustrates what we would expect when the distribution accurately captures the process; the second is an example of a graphic indicating the distributional assumptions are incorrect.
#| fig-alt: Several density plots overlaid with one highlighted for comparison.
#| echo: false
set.seed(20220110)

fakesample <- tibble(
  y = rexp(100, rate = 3)
)

fakepost <- tibble(
  variate = seq(1000),
  lambdapost = rgamma(1000, shape = 100 + 1, rate = sum(fakesample$y))
) |>
  mutate(postpred = map(lambdapost, ~ rexp(100, rate = .x)),
         postbad = map(lambdapost, ~ rnorm(100, mean = 1 / .x, sd = 1 / .x))) |>
  unnest(cols = c(postpred, postbad)) |>
  pivot_longer(cols = c(postpred, postbad),
               values_to = 'posterior',
               names_to = 'type') |>
  mutate(type = recode(type,
                        'postpred' = 'Accurate Model',
                        'postbad' = 'Inaccurate Model'))

ggplot(data = fakepost,
       mapping = aes(x = posterior)) +
  geom_density(mapping = aes(group = variate),
               color = 'lightblue', alpha = 0.5) +
  geom_density(data = fakesample,
               mapping = aes(x = y),
               color = 'black', linewidth = 1.1) +
  labs(y = 'Density', 
       x = 'Response') +
  facet_wrap(~ type, scales = 'free') +
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank())
```

:::{.callout-note}
## Assessing the Likelihood
If the model for the likelihood is correctly specified, then the marginal distribution of the observed response should be similar to the posterior predictive distribution given the observed data.  For a regression model, this is done by generating several _samples_ of the same size given the posterior variates; if the distributional model is appropriate, a density plot of the observed response should line up with the density plots of those samples generated from the posterior variates.  Any major differences in these shapes would suggest _some_ aspect of the model (including the distributional form) is incorrect.
:::

:::{#exm-therapy-postpred}
## Rehabilitation Therapy Continued
@exm-therapy-mean0 presented a model for the study described in @exm-therapy.  @fig-postpredcond is a plot of the posterior predicted distribution of the responses (using 250 randomly selected posterior variates) against the observed distribution of the response.  Comment on the assumption that the distributional model specified is appropriate.
:::

```{r}
#| echo: false
#| eval: true
#| label: fig-postpredcond
#| fig-cap: Assessment of the distributional assumptions for the Therapy example.
#| fig-alt: Overlaid densities with one highlighted

set.seed(20231028)
params <- stan_to_df(fit.therapy) |>
  slice_sample(n = 250, replace = FALSE)


predictions <- tibble()

for (m in 1:nrow(params)) {
  scale <- params$beta0[m] + params$beta1[m] * therapy.df$Age

  df <- tibble(
    replication = m,
    yhat = rexp(nrow(therapy.df), rate = 1/scale)
  )

  predictions <- bind_rows(predictions, df)
}

ggplot(data = predictions,
       mapping = aes(x = yhat)) +
  geom_density(mapping = aes(group = replication),
               color = 'lightblue', alpha = 0.5) +
  geom_density(data = therapy.df,
               mapping = aes(x = Recovery),
               color = 'black', linewidth = 1.1) +
  labs(y = 'Density', 
       x = 'Recovery Time (Days)') +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
```

:::{.solution}
The observed marginal distribution of the response is very different than the predicted distributions.  While this could be due in part to the misspecification of the mean response model (as noted in @exm-therapy-mean0), the level of departure here suggests the distributional assumption on the likelihood is also incorrect.  If we wanted to be sure, we should refit the model using a different mean response function first, and then repeat this process.
:::
