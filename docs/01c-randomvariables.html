<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bayesian Data Analysis - 2&nbsp; Random Variables and Distributions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./02a-language.html" rel="next">
<link href="./01b-fundamentals.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="mystyles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01a-probability.html">Unit I: Essential Probability</a></li><li class="breadcrumb-item"><a href="./01c-randomvariables.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Random Variables and Distributions</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Data Analysis</a> 
        <div class="sidebar-tools-main">
    <a href="./ma483-text.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./01a-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit I: Essential Probability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01b-fundamentals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Essential Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01c-randomvariables.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Random Variables and Distributions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./02a-language.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit II: Language of Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02b-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Statistical Process</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02c-casedeepwater.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Case Study: Health Effects of the Deepwater Horizon Oil Spill</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02d-questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Asking the Right Questions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02e-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Gathering the Evidence (Data Collection)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02f-summaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Presenting the Evidence (Summarizing Data)</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./03a-fundamentals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit III: Fundamentals of Bayesian Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03b-bayesrule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Bayes Rule</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03c-modelingsamples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Modeling Samples</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03d-priors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Quantifying/Modeling Prior Information</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03e-posteriors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Updating Prior Beliefs (Posterior Distributions)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03f-point-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Point Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03g-interval-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Interval Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03h-prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03i-hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03j-constructing-priors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Constructing Prior Distributions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./04a-computation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit IV: Numerical Approaches to Bayesian Computations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04b-mc-integration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Monte Carlo Integration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04c-mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Markov Chain Monte Carlo (MCMC)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04d-mcmc-assessment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Assessing MCMC Samples</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./05a-comparing-groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit V: Hierarchical Models for Comparing Groups</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05b-study-design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Elements of Good Study Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05c-independent-groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Considerations when Comparing Independent Groups</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05d-dependent-groups.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Considerations when Comparing Related Groups</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./06a-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit VI: Introduction to Regression Modeling</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06b-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Regression Models for a Quantitative Response</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06c-reg-extensions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Extensions to the Linear Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06d-reg-priors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Default Priors in Regression Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06e-qr-factorization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">QR Factorization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06f-reg-conditions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Assessment for Regression Models for the Mean</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06g-categorical-reg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Regression Models for Categorical Responses</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./app-glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Glossary</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#random-variables" id="toc-random-variables" class="nav-link active" data-scroll-target="#random-variables"><span class="header-section-number">2.1</span> Random Variables</a></li>
  <li><a href="#characterizing-a-distribution" id="toc-characterizing-a-distribution" class="nav-link" data-scroll-target="#characterizing-a-distribution"><span class="header-section-number">2.2</span> Characterizing a Distribution</a>
  <ul class="collapse">
  <li><a href="#common-parameters" id="toc-common-parameters" class="nav-link" data-scroll-target="#common-parameters"><span class="header-section-number">2.2.1</span> Common Parameters</a></li>
  <li><a href="#kernels" id="toc-kernels" class="nav-link" data-scroll-target="#kernels"><span class="header-section-number">2.2.2</span> Kernels</a></li>
  <li><a href="#distribution-function" id="toc-distribution-function" class="nav-link" data-scroll-target="#distribution-function"><span class="header-section-number">2.2.3</span> Distribution Function</a></li>
  </ul></li>
  <li><a href="#transformations-of-a-random-variable" id="toc-transformations-of-a-random-variable" class="nav-link" data-scroll-target="#transformations-of-a-random-variable"><span class="header-section-number">2.3</span> Transformations of a Random Variable</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-randomvariables" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Random Variables and Distributions</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In <a href="01b-fundamentals.html"><span>Chapter&nbsp;1</span></a>, we discussed the probability of an “event.” For statisticians, the events of interests center on measurements, or functions of those measurements, that we plan to take. In this chapter, we begin to connect probability to data analysis. Our goal is to reexamine concepts introduced in a probability course, relating them to their data-centric analogues, which will be discussed further in the next unit.</p>
<section id="random-variables" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="random-variables"><span class="header-section-number">2.1</span> Random Variables</h2>
<p>Consider collecting data; before the data is collected, we cannot predict with certainty what we will observe. Therefore, we can think of each observation as the result of a random process. These observations are recorded as variables in our dataset. In probability, a <strong>random variable</strong> is used to represent a measurement that results from a random process.</p>
<div id="def-random-variable" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.1 (Random Variable) </strong></span>Let <span class="math inline">\(\mathcal{S}\)</span> be the sample space corresponding to a random process; a random variable <span class="math inline">\(X\)</span> is a function mapping elements of the sample space to the real line.</p>
<p>Random variables represent a measurement that will be collected during the course of a study. Random variables are typically represented by a capital letter.</p>
</div>
<p>While for our purposes, it suffices to think of a random variable as a measurement, mathematically, it is a <em>function</em>. The image (or range) of this function is used to broadly classify random variables as <strong>continuous</strong> or <strong>discrete</strong>; we refer to this image as the <strong>support</strong> of the random variable.</p>
<div id="def-support" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.2 (Support) </strong></span>The support of a random variable is the set of all possible values the random variable can take.</p>
</div>
<div id="def-rvtypes" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.3 (Continuous and Discrete Random Variable) </strong></span>The random variable <span class="math inline">\(X\)</span> is said to be a discrete random variable if its corresponding support is countable. The random variable <span class="math inline">\(X\)</span> is said to be a continuous random variable if the corresponding support is uncountable (such as an interval or a union of intervals on the real line).</p>
</div>
<p>Discrete random variables are analogous to categorical (or qualitative) variables in data analysis; that is, discrete random variables are used to model the result of a random process which categorizes each unit of observation into a group. Continuous random variables are analogous to numeric (or quantitative) variables in data analysis; continuous random variables are used to model the result of a random process which produces a number for which arithmetic makes sense.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Whether we use a continuous or discrete random variable to represent a measurement is not always obvious. Suppose we consider recording the age of a student selected from a class at a university that typically enrolls “traditional” students (those coming directly from high school). Let the random variable <span class="math inline">\(X\)</span> denote the age of the student.</p>
<p>If we record the student’s age in years since birth, <span class="math inline">\(X\)</span> can take on only a finite number of values (most likely <span class="math inline">\(\{18, 19, 20, 21, 22, 23\}\)</span>), making it a discrete random variable. However, if we record the student’s age as the number of seconds since birth, we might well consider the support of <span class="math inline">\(X\)</span> to be a rather large interval, leading to a continuous random variable.</p>
</div>
</div>
<p>The goal of statistics is to use a sample to say something about the underlying population. Consider taking a sample of size <span class="math inline">\(n\)</span> and measuring a single variable on each unit of observation. Then, we might represent the measurements we will obtain (note the use of the future tense) as <span class="math inline">\(X_1, X_2, \dots, X_n\)</span>. While the majority of probability courses focus on a single, or maybe two, random variables, note that collecting data on a sample requires that we deal with at least <span class="math inline">\(n\)</span> random variables (one measurement for each of the observations in our sample).</p>
</section>
<section id="characterizing-a-distribution" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="characterizing-a-distribution"><span class="header-section-number">2.2</span> Characterizing a Distribution</h2>
<p>Again, the goal of statistics is to use a sample to say something about the underlying population. Consider the following research objective:</p>
<blockquote class="blockquote">
<p>Estimate the cost (in US dollars) of a diamond for sale in the United States.</p>
</blockquote>
<p>For this research objective, our population of interest is all diamonds for sale in the United States. We would not expect every diamond for sale to have the same price; variability is inherent in any process. As a result, the sale price of diamonds has a distribution across this population. This is our primary use of probability theory in a statistical analysis — to model distributions.</p>
<p>Consider taking a sample of size 1 from the population; let <span class="math inline">\(Y\)</span> represent the cost of the diamond that is selected. Since we have not yet observed the cost of this diamond, <span class="math inline">\(Y\)</span> is a random variable. And, since this diamond is sampled from the population of interest, the support of <span class="math inline">\(Y\)</span> is determined by the cost of diamonds in the United States. Further, the likelihood that <span class="math inline">\(Y\)</span> falls within any interval is determined by the distribution of the cost across the population. That is, the distribution of <span class="math inline">\(Y\)</span> is the distribution of the population.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Big Idea
</div>
</div>
<div class="callout-body-container callout-body">
<p>If a random variable <span class="math inline">\(X\)</span> represents a measurement for a single observation from a population, the distribution of the random variable corresponds to the distribution of the variable across the population.</p>
</div>
</div>
<p>A key realization in statistical analysis is that we will never fully observe the distribution of the population; however, we can posit a model for this distribution. In probability, the most common way to characterize the distribution of a random variable is through its density function.</p>
<div id="def-density-function" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.4 (Density Function) </strong></span>A density function <span class="math inline">\(f\)</span> relates the values in the support of a random variable with the probability of observing those values.</p>
<p>Let <span class="math inline">\(X\)</span> be a continuous random variable, then its density function <span class="math inline">\(f\)</span> is the function such that</p>
<p><span class="math display">\[Pr(a \leq X \leq b) = \int_a^b f(x) dx\]</span></p>
<p>for any real numbers <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> in the support.</p>
<p>Let <span class="math inline">\(X\)</span> be a discrete random variable, then its density function <span class="math inline">\(f\)</span> is the function such that</p>
<p><span class="math display">\[Pr(X = u) = f(u)\]</span></p>
<p>for any real number <span class="math inline">\(u\)</span> in the support.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Properties of a Density Function
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <span class="math inline">\(X\)</span> be a random variable with density function <span class="math inline">\(f\)</span> defined over support <span class="math inline">\(\mathcal{S}\)</span>. Then,</p>
<ol type="1">
<li><span class="math inline">\(f(x) \geq 0\)</span> for all <span class="math inline">\(x \in \mathcal{S}\)</span>. That is, the density is non-negative for all values in the support.</li>
<li>If <span class="math inline">\(X\)</span> is a continuous random variable, then <span class="math inline">\(\int_{\mathcal{S}} f(x) dx = 1\)</span>; similarly, if <span class="math inline">\(X\)</span> is a discrete random variable, then <span class="math inline">\(\sum_{\mathcal{S}} f(x) = 1\)</span>. That is, <span class="math inline">\(X\)</span> must take a value in its support; so, <span class="math inline">\(Pr(X \in \mathcal{S}) = 1\)</span>, similar to the second Axiom of Probability (<a href="01b-fundamentals.html#def-axioms">Definition&nbsp;<span>1.3</span></a>).</li>
<li><span class="math inline">\(f(x) = 0\)</span> for all values of <span class="math inline">\(x \notin \mathcal{S}\)</span>. The density takes the value of 0 for all values outside the support.</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In a probability course, there is often a distinction made between probability “density” functions (used for continuous random variables) and probability “mass” functions (used for discrete random variables). We do not make this distinction and instead rely on the context to determine whether we are dealing with a continuous or discrete random variable. Throughout, we will note when the operations differ between these two types of variables. Measure theory provides a unifying framework to these issues.</p>
</div>
</div>
<p>When working with a continuous random variable, the density function is a smooth function over some region, and the actual value of the function is not interpretable; instead, we get at a probability by considering the area under the curve. Again, drawing connections to data analysis, we can think of a density function as a mathematical formula representing a smooth histogram. The area under the curve for any region gives the proportion of the population which has a value in that region. That is, we get the probability that a random variable will be in an interval by integrating the density function over that interval.</p>
<p>Figure <a href="#fig-randomvariables-density">Figure&nbsp;<span>2.1</span></a> illustrates this idea; we have data from a sample of diamonds from the population of interest. The sample is summarized with a histogram; we have overlayed a posited density (with the corresponding mathematical function that describes this density) for the population. The sample (summarized with the histogram) is approximating the population (modeled using the density function).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-randomvariables-density" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./images/fig-randomvariables-density-1.png" class="img-fluid figure-img" style="width:80.0%" alt="Histogram with a density function overlayed."></p>
<figcaption class="figure-caption">Figure&nbsp;2.1: Illustration of a density function representing the posited distribution of the population alongside a histogram summarizing the cost of diamonds using a sample of 53940 diamonds.</figcaption>
</figure>
</div>
</div>
</div>
<p>You may recognize the particular form of the density function in <a href="#fig-randomvariables-density">Figure&nbsp;<span>2.1</span></a>. The general form is</p>
<p><span class="math display">\[f(x) = \frac{1}{\sigma} e^{-x / \sigma} \qquad \text{for } x &gt; 0\]</span></p>
<p>where <span class="math inline">\(\sigma\)</span> is the <em>scale</em> parameter that defines the distribution (set at 4000 in <a href="#fig-randomvariables-density">Figure&nbsp;<span>2.1</span></a>). This is known as the Exponential distribution with scale parameter <span class="math inline">\(\sigma\)</span>. This illuminates another connection between probability and statistics.</p>
<p>Note that our research objective describe above is an ill-posed question as stated. The answer is “it depends” since each individual diamond in the population has a different value. Well-posed questions in statistics are centered on an appropriately chosen <strong>parameter</strong> (<a href="02d-questions.html#def-parameter">Definition&nbsp;<span>5.6</span></a>).</p>
<p>In probability, the parameters are values that are tuned or set within a problem; we then work forward to compute the probability of an event of interest. In practice, however, when we posit a functional form for a density function to describe the distribution of the population, the parameters are unknown. We plan to use the data to estimate or characterize the parameter; but, the parameter itself will remain unknown. In both cases, however, the parameter is a <em>fixed quantity</em>, even if we are ignorant of that value.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Big Idea
</div>
</div>
<div class="callout-body-container callout-body">
<p>When a probability model is specified for a population, it is generally specified up to some unknown parameter(s). Making inference on the unknown parameter(s) therefore characterizes the entire distribution.</p>
</div>
</div>
<section id="common-parameters" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="common-parameters"><span class="header-section-number">2.2.1</span> Common Parameters</h3>
<p>Most scientific questions are focused on the location or spread of a distribution. For example, we are interested in estimating the average cost of a diamond sold in the United States. Introductory statistics introduces summaries of location and spread within the sample (e.g., sample mean for location and sample variance for spread). Analogous summaries exist for density functions. As stated above, parameters are unknown constants that govern the form of the density function. Because they govern the form of the density, the parameters are also related to those summarizing the location or spread of the distribution.</p>
<div id="def-mean" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.5 (Expected Value (Mean)) </strong></span>Let <span class="math inline">\(X\)</span> be a random variable with density function <span class="math inline">\(f\)</span> defined over the support <span class="math inline">\(\mathcal{S}\)</span>. The expected value of a random variable, also called the mean and denoted <span class="math inline">\(E(X)\)</span>, is given by</p>
<p><span class="math display">\[E(X) = \int_{\mathcal{S}} x f(x) dx\]</span></p>
<p>for continuous random variables and</p>
<p><span class="math display">\[E(X) = \sum_{\mathcal{S}} x f(x)\]</span></p>
<p>for discrete random variables.</p>
</div>
<p>Notice the similarity between the form of the sample mean and the population mean. A sample mean takes the sum of each value in the sample, weighting each value by <span class="math inline">\(1/n\)</span> (where <span class="math inline">\(n\)</span> is the sample size). Without information about the underlying population, the sample must treat each value observed as equally likely; values become more likely if they appear multiple times. In the population, however, when the form of <span class="math inline">\(f\)</span> is known, the density provides information about the likelihood of each value giving us a better weight than <span class="math inline">\(1/n\)</span>. That is, the population mean is a sum of the values in the support, weighting each value by the corresponding value of the density function.</p>
<div id="def-variance" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.6 (Variance) </strong></span>Let <span class="math inline">\(X\)</span> be a random variable with density function <span class="math inline">\(f\)</span> defined over the support <span class="math inline">\(\mathcal{S}\)</span>. The variance of a random variable, denoted <span class="math inline">\(Var(X)\)</span>, is given by</p>
<p><span class="math display">\[Var(X) = E\left[X - E(X)\right]^2 = E\left(X^2\right) - E^2(X).\]</span></p>
<p>If we let <span class="math inline">\(\mu = E(X)\)</span>, then this is equivalent to</p>
<p><span class="math display">\[\int_{\mathcal{S}} (x - \mu)^2 f(x) dx\]</span></p>
<p>for continuous random variables and</p>
<p><span class="math display">\[\sum_{\mathcal{S}} (x - \mu)^2 f(x)\]</span></p>
<p>for discrete random variables.</p>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pay careful attention to the notation. <span class="math inline">\(E^2(X)\)</span> represents the square of the expected value; that is,</p>
<p><span class="math display">\[E^2(X) = \left[E(X)\right]^2.\]</span></p>
<p>However, <span class="math inline">\(E(X)^2\)</span> represents the expected value of the square of <span class="math inline">\(X\)</span>; that is,</p>
<p><span class="math display">\[E(X)^2 = E\left(X^2\right).\]</span></p>
</div>
</div>
<p>The variance provides a measure of spread; in particular, it is capturing distance from the mean. Notice that the form of the variance involves taking the expectation of a squared term; in general, we will need to consider expectations of functions.</p>
<div id="def-expectation" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.7 (Expectation of a Function) </strong></span>Let <span class="math inline">\(X\)</span> be a random variable with density function <span class="math inline">\(f\)</span> over the support <span class="math inline">\(\mathcal{S}\)</span>, and let <span class="math inline">\(g\)</span> be a real-valued function. Then,</p>
<p><span class="math display">\[E\left[g(X)\right] = \int_{\mathcal{S}} g(x) f(x) dx\]</span></p>
<p>for continuous random variables and</p>
<p><span class="math display">\[E\left[g(X)\right] = \sum_{\mathcal{S}} g(x) f(x)\]</span></p>
<p>for discrete random variables.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="#def-expectation">Definition&nbsp;<span>2.7</span></a> is sometimes referred to as the “Law of the Unconscious Statistician” in probability texts. We find the name somewhat insulting, as it suggests statisticians do not appreciate the mathematical underpinnings of their field. In reality, the expected value of a function is such a common operation in statistical theory that statisticians often present <a href="#def-expectation">Definition&nbsp;<span>2.7</span></a> as the definition of an expectation (as we have done) instead of deriving it as a result of <a href="#def-mean">Definition&nbsp;<span>2.5</span></a> after applying a variable transformation (see <a href="#exm-transformations">Example&nbsp;<span>2.3</span></a> below). It is possible this is where the slight in the naming convention originated.</p>
</div>
</div>
<p>A result of <a href="#def-expectation">Definition&nbsp;<span>2.7</span></a> is the following, very useful theorem, which states that expectations are linear operators.</p>
<div id="thm-expectation" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2.1 (Expectation of a Linear Combination) </strong></span>Let <span class="math inline">\(X\)</span> be a random variable, and let <span class="math inline">\(a_1, a_2, \dotsc, a_m\)</span> be real-valued constants and <span class="math inline">\(g_1, g_2, \dotsc, g_m\)</span> be real-valued functions; then,</p>
<p><span class="math display">\[E\left[\sum_{i=1}^{m} a_i g_i(X)\right] = \sum_{i=1}^{m} a_i E\left[g_i(X)\right].\]</span></p>
</div>
<p>The mean and variance play an important role in characterizing a distribution, especially within statistical theory (as we will see in future chapters). However, there is another set of parameters which are important.</p>
<div id="def-population-percentile" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.8 (Percentile for a Random Variable) </strong></span>Let <span class="math inline">\(X\)</span> be a random variable with density function <span class="math inline">\(f\)</span>. The <span class="math inline">\(100k\)</span> percentile is the value <span class="math inline">\(q\)</span> such that</p>
<p><span class="math display">\[Pr(X \leq q) = k.\]</span></p>
</div>
<div id="exm-parameters" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.1 (Parameters of Exponential Distribution) </strong></span>Let <span class="math inline">\(X\)</span> be an Exponential distribution with scale parameter <span class="math inline">\(\sigma\)</span>; that is, the density function <span class="math inline">\(f\)</span> is given by</p>
<p><span class="math display">\[f(x) = \frac{1}{\sigma} e^{-x/\sigma} \qquad x &gt; 0\]</span></p>
<p>where <span class="math inline">\(\sigma &gt; 0.\)</span> Compute the mean, variance, and median of this distribution, as a function of the unknown scale parameter.</p>
</div>
<p>The solution to this problem is particularly important as it illustrates a very useful technique when working with known distributions in statistical theory.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>We note that the function</p>
<p><span class="math display">\[g(y) = \frac{1}{\beta^{\alpha} \Gamma(\alpha)} y^{\alpha - 1} e^{-y/\beta}\]</span></p>
<p>is a valid density function over the positive real line provided that <span class="math inline">\(\alpha,\beta &gt; 0\)</span>; in particular, this is known as a Gamma distribution. Since <span class="math inline">\(g\)</span> is a valid density function, then we know that</p>
<p><span class="math display">\[\int_{0}^{\infty} g(y) dy = 1\]</span></p>
<p>for all values of <span class="math inline">\(\alpha,\beta &gt; 0\)</span>.</p>
<p>Now, let <span class="math inline">\(X\)</span> be an Exponential random random variable with scale parameter <span class="math inline">\(\sigma\)</span>. Then, the expected value of <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[
\begin{aligned}
  E(X)
    &amp;= \int_{0}^{\infty} x \frac{1}{\sigma} e^{-x/\sigma} dx \\
    &amp;= \int_{0}^{\infty} \frac{1}{\sigma} x^{2-1} e^{-x/\sigma} dx
\end{aligned}
\]</span></p>
<p>where we have simply rewritten the exponent in the second line. Notice that expression within the integral shares a striking similarity to the form of the density function of a Gamma distribution; however, they are not exactly the same. To coerce the expression into that of the Gamma density function, we “do nothing” — multiplying and dividing the expression by the quantity <span class="math inline">\(\sigma\Gamma(2)\)</span>. This gives</p>
<p><span class="math display">\[
\begin{aligned}
  E(X)
    &amp;= \int_{0}^{\infty} x \frac{1}{\sigma} e^{-x/\sigma} dx \\
    &amp;= \int_{0}^{\infty} \frac{1}{\sigma} x^{2-1} e^{-x/\sigma} dx \\
    &amp;= \int_{0}^{\infty} \sigma \Gamma(2) \frac{1}{\sigma^2 \Gamma(2)} x^{2-1} e^{-x/\sigma} dx \\
    &amp;= \sigma \Gamma(2) \int_{0}^{\infty} \frac{1}{\sigma^2 \Gamma(2)} x^{2-1} e^{-x/\sigma} dx \\
    &amp;= \sigma \Gamma(2) \\
    &amp;= \sigma.
\end{aligned}
\]</span></p>
<p>In line 3, we have multiplied and divided by <span class="math inline">\(\sigma \Gamma(2)\)</span>, which does not change the problem. In line 4, we have pulled out the terms <span class="math inline">\(\sigma \Gamma(2)\)</span> since it is a constant with respect to the integral; what is left inside the integral is the form of the density function for a Gamma distribution where <span class="math inline">\(\alpha = 2\)</span> and <span class="math inline">\(\beta = \sigma\)</span>. In line 5, we make use of the fact that the integral of any density function over the entire support for which it is defined must be 1. Finally, in line 6, we recognize that <span class="math inline">\(\Gamma(k) = (k-1)!\)</span> if <span class="math inline">\(k\)</span> is a natural number.</p>
<p>Applying the same process, we also have that</p>
<p><span class="math display">\[
\begin{aligned}
  E\left(X^2\right)
    &amp;= \int_{0}^{\infty} x^2 \frac{1}{\sigma} e^{-x/\sigma} dx \\
    &amp;= \sigma^2 \Gamma(3)\int_{0}^{\infty} \frac{1}{\sigma^3 \Gamma(3)} x^{3-1} e^{-x/\sigma} dx \\
    &amp;= 2\sigma^2.
\end{aligned}
\]</span></p>
<p>Therefore,</p>
<p><span class="math display">\[Var(X) = E\left(X^2\right) - E^2(X) = 2\sigma^2 - \sigma^2 = \sigma^2.\]</span></p>
<p>Finally, the median is the value <span class="math inline">\(q\)</span> such that <span class="math inline">\(Pr(X \leq q) = 0.5\)</span>; but, we recognize that</p>
<p><span class="math display">\[
\begin{aligned}
  Pr(X \leq q)
    &amp;= \int_{0}^{q} \frac{1}{\sigma} e^{-x/\sigma} dx \\
    &amp;= \left. -e^{-x/\sigma} \right|_{0}^{q} \\
    &amp;= -e^{-q/\sigma} + 1.
\end{aligned}
\]</span></p>
<p>Setting this expression equal to 0.5 and solving for <span class="math inline">\(q\)</span> yields <span class="math inline">\(q = -\sigma \log(0.5)\)</span>, where <span class="math inline">\(\log(\cdot)\)</span> represents the <em>natural</em> logarithm.</p>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Big Idea
</div>
</div>
<div class="callout-body-container callout-body">
<p>Suppose the density <span class="math inline">\(f\)</span> is a function of the parameters <span class="math inline">\(\boldsymbol{\theta}\)</span>; then, the mean, variance, and median (as well as any other parameters of interest in a research objective) will be functions of <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
</div>
</div>
<p><a href="#exm-parameters">Example&nbsp;<span>2.1</span></a> highlighted a useful technique for simplifying integrals in statistical applications, which makes use of the “do nothing” strategy discussed in the previous chapter.</p>
</section>
<section id="kernels" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="kernels"><span class="header-section-number">2.2.2</span> Kernels</h3>
<p>One of the characteristics common to any density function that we noted above was that if we sum the density across the entire support, we get a value of 1. That is, if <span class="math inline">\(X\)</span> is a discrete random variable, then</p>
<p><span class="math display">\[\sum_{x \in \mathcal{S}_X} f(x) = 1,\]</span></p>
<p>and if <span class="math inline">\(X\)</span> is a continuous random variable, then</p>
<p><span class="math display">\[\int_{\mathcal{S}_X} f(x) dx = 1.\]</span></p>
<p>Any density function can be written as</p>
<p><span class="math display">\[f(x) = a k(x)\]</span></p>
<p>where <span class="math inline">\(a &gt; 0\)</span> is a constant and <span class="math inline">\(k(x)\)</span> is a function of <span class="math inline">\(x\)</span>. Specifically, if <span class="math inline">\(X\)</span> is a continuous random variable, then</p>
<p><span class="math display">\[a = \frac{1}{\int k(x) dx}\]</span></p>
<p>since <span class="math inline">\(\int f(x) dx = 1\)</span>. We call <span class="math inline">\(k(x)\)</span> the <strong>kernel</strong> of the distribution. Kernels are helpful for quickly identifying distributions<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<div id="def-kernel" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.9 (Kernel of a Distribution) </strong></span>Let <span class="math inline">\(k(x)\)</span> be a non-negative function of <span class="math inline">\(x\)</span> over some region <span class="math inline">\(\mathcal{S}_X\)</span>. Then, a valid density function <span class="math inline">\(f\)</span> over the support <span class="math inline">\(\mathcal{S}_X\)</span> can be constructed by taking</p>
<p><span class="math display">\[f(x) = a k(x)\]</span></p>
<p>where <span class="math inline">\(a &gt; 0\)</span> is a suitably chosen scaling constant to ensure the density integrates (or sums) to 1 over the support. The function <span class="math inline">\(k\)</span> is known as the kernel of the distribution, and it can be used to identify the distributional family for a random variable.</p>
</div>
<div id="exm-kernel" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.2 (Kernel of an Exponential Random Variable) </strong></span>In <a href="#exm-parameters">Example&nbsp;<span>2.1</span></a>, we let <span class="math inline">\(X\)</span> be an Exponential random variable with scale parameter <span class="math inline">\(\sigma\)</span>. Identify the kernel of this distribution.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>Let <span class="math inline">\(a = \sigma^{-1}\)</span> and</p>
<p><span class="math display">\[k(x) = e^{-x/\sigma};\]</span></p>
<p>then, we have that <span class="math inline">\(f(x) = a k(x)\)</span>. We note that <span class="math inline">\(k(x)\)</span> has no leading constants; therefore, the kernel for an Exponential distribution is</p>
<p><span class="math display">\[e^{-x/\sigma}.\]</span></p>
</div>
<p>As <a href="#exm-parameters">Example&nbsp;<span>2.1</span></a> illustrated, being able to identify a kernel can help us quickly evaluate an integral. In particular, notice that we immediately have that</p>
<p><span class="math display">\[\int e^{-x/\sigma} dx = \sigma\]</span></p>
<p>for any value of <span class="math inline">\(\sigma &gt; 0\)</span> because we know that</p>
<p><span class="math display">\[
\begin{aligned}
  \int e^{-x / \sigma} dx
    &amp;= \sigma \int \frac{1}{\sigma} e^{-x / \sigma} dx \\
    &amp;= \sigma.
\end{aligned}
\]</span></p>
<p>The first line multiplies and divides by the appropriate scaling term so that the kernel becomes a valid density function. Once we have a valid density, we know it integrates to 1, simplifying the expression.</p>
<p>In addition to motivating the use of kernels in integration applications, the solution to <a href="#exm-parameters">Example&nbsp;<span>2.1</span></a> also shows that there is more than one way to characterize a distribution.</p>
</section>
<section id="distribution-function" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="distribution-function"><span class="header-section-number">2.2.3</span> Distribution Function</h3>
<p>Especially for visualization, the density function is the most common way of characterizing a probability model. However, computing the probability using the density is problematic due to the integration required. Many software address this by working with the cumulative distribution function (CDF).</p>
<div id="def-cdf" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.10 (Cumulative Distribution Function (CDF)) </strong></span>Let <span class="math inline">\(X\)</span> be a random variable; the cumulative distribution function (CDF) is defined as</p>
<p><span class="math display">\[F(u) = Pr(X \leq u).\]</span></p>
<p>For a continuous random variable, we have that</p>
<p><span class="math display">\[F(u) = \int_{-\infty}^{u} f(x) dx\]</span></p>
<p>implying that the density function is the derivative of the CDF. For a discrete random variable</p>
<p><span class="math display">\[F(u) = \sum_{x \leq u} f(x).\]</span></p>
</div>
<p>Working with the CDF improves computation because it avoids the need to integrate each time; instead, the integral is computed once (and stored internally in the computer) and we use the result to compute probabilities directly.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Big Idea
</div>
</div>
<div class="callout-body-container callout-body">
<p>Density functions are the mathematical models for distributions; they link values of the variable with the likelihood of occurrence. However, for computational reasons, we often work with the cumulative distribution function which provides the probability of being less than or equal to a value.</p>
</div>
</div>
</section>
</section>
<section id="transformations-of-a-random-variable" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="transformations-of-a-random-variable"><span class="header-section-number">2.3</span> Transformations of a Random Variable</h2>
<p>Occasionally, we are interested in a transformation of a particular characteristic. That is, we have a model for the distribution of <span class="math inline">\(X\)</span>, but we are interested in <span class="math inline">\(Y = g(X)\)</span>. In this section, we examine one method for determining the density of <span class="math inline">\(Y\)</span> from the density of <span class="math inline">\(X\)</span>. While relationships between many common distributions have been well studied<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, it is useful to know the process for addressing transformations.</p>
<p>While there various approaches to this problem, we find this method the most reliable. Further, it does not require the memorization of a formula, but instead builds on fundamental ideals. This is known as the <strong>Method of Distribution Functions</strong>.</p>
<div id="def-method-of-distribution-functions" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.11 (Method of Distribution Functions) </strong></span>Let <span class="math inline">\(X\)</span> be a continuous random variable with density <span class="math inline">\(f\)</span> and cumulative distribution function <span class="math inline">\(F\)</span>. Consider <span class="math inline">\(Y = h(X)\)</span>. The following process provides the density function <span class="math inline">\(g\)</span> of <span class="math inline">\(Y\)</span> by first finding its cumulative distribution function <span class="math inline">\(G\)</span>.</p>
<ol type="1">
<li>Find the set <span class="math inline">\(A\)</span> for which <span class="math inline">\(h(X) \leq t\)</span> if and only if <span class="math inline">\(X \in A\)</span>.</li>
<li>Recognize that <span class="math inline">\(G(y) = Pr(Y \leq y) = Pr\left(h(X) \leq y\right) = Pr(X \in A)\)</span>.</li>
<li>If interested in <span class="math inline">\(g(y)\)</span>, note that <span class="math inline">\(g(y) = \frac{\partial}{\partial y} G(y)\)</span>.</li>
</ol>
</div>
<p>When <span class="math inline">\(h\)</span> is a strictly monotone function (unique inverse exists), then step 1-2 is much easier because we can apply <span class="math inline">\(h^{-1}\)</span>. In step 2 of the above process, the final expression is often left in terms of <span class="math inline">\(F\)</span>, the CDF of <span class="math inline">\(X\)</span>; then, when we find the density in step 3, we can apply the chain rule (avoiding the need to actually have an expression for <span class="math inline">\(F\)</span>).</p>
<div id="exm-transformations" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.3 (Transformation of a Random Variable) </strong></span>Previously, we posited the following model for the distribution of the cost of a diamond sold in the US:</p>
<p><span class="math display">\[f(x) = \frac{1}{\sigma} e^{-x/\sigma} \qquad x &gt; 0\]</span></p>
<p>for some <span class="math inline">\(\sigma &gt; 0\)</span>. As cost is generally a heavily skewed variable, we may be interested in taking the (natural) logarithm before proceeding with an analysis. Find the density of <span class="math inline">\(Y = \log(X)\)</span>; then, write an expression for <span class="math inline">\(E(Y)\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>We note that <span class="math inline">\(\log(x)\)</span> is a strictly monotone function. Therefore, we have that</p>
<p><span class="math display">\[
\begin{aligned}
  G(y) &amp;= Pr(Y \leq y) \\
    &amp;= Pr(\log(X) \leq y) \\
    &amp;= Pr\left(X \leq e^y\right).
\end{aligned}
\]</span></p>
<p>Just to place this within the method described above, since <span class="math inline">\(\log(x) \leq y\)</span> if and only if <span class="math inline">\(x \leq e^y\)</span>, then <span class="math inline">\(A = \{t: x \leq e^t\}\)</span>. Of course, we didn’t really need to identify this because we were able to apply the inverse of <span class="math inline">\(\log(x)\)</span> directly within the probability expression. We now recognize that we have a probability of the form “<span class="math inline">\(X\)</span> less than or equal to something.” And, this matches the form of the CDF of <span class="math inline">\(X\)</span>. That is, we have that</p>
<p><span class="math display">\[G(y) = F\left(e^y\right).\]</span></p>
<p>This completes step 2 of the procedure; we have expressed the CDF of <span class="math inline">\(Y\)</span> as a function of the CDF of <span class="math inline">\(X\)</span>. Now, to find the density, we apply the chain rule.</p>
<p><span class="math display">\[
\begin{aligned}
  g(y)
    &amp;= \frac{\partial}{\partial y} G(y) \\
    &amp;= \left[\left.\frac{\partial}{\partial x} F(x)\right|_{x = e^y}\right] \frac{\partial}{\partial y} e^y \\
    &amp;= \left[\left. f(x) \right|_{x = e^y}\right] e^y \\
    &amp;= f\left(e^y\right) e^y \\
    &amp;= \frac{1}{\sigma} e^{-e^y/\sigma} e^y
\end{aligned}
\]</span></p>
<p>which will be valid for all real values of <span class="math inline">\(y\)</span>; that is, the support of <span class="math inline">\(Y\)</span> is all real numbers. In line 2 above, we applied the chain rule to compute the derivative, avoiding the need to explicitly state the CDF of <span class="math inline">\(X\)</span>.</p>
<p>Given the density of <span class="math inline">\(Y\)</span>, we know (by <a href="#def-mean">Definition&nbsp;<span>2.5</span></a>) that</p>
<p><span class="math display">\[E(Y) = \int y g(y) dy = \int y \frac{1}{\sigma} e^{-e^{y}/\sigma} e^{y} dy.\]</span></p>
<p>Letting <span class="math inline">\(u = e^y\)</span> (and therefore <span class="math inline">\(du = e^y dy\)</span>) and performing a u-substitution, we have that</p>
<p><span class="math display">\[
\begin{aligned}
  E(Y)
    &amp;= \int y\frac{1}{\sigma} e^{-e^{y}/\sigma} e^{y} dy \\
    &amp;= \int \log(u) \frac{1}{\sigma} e^{-u / \sigma} du.
\end{aligned}
\]</span></p>
<p>Since the variable of integration is arbitrary, we recognize that this integral as what we defined (in <a href="#def-expectation">Definition&nbsp;<span>2.7</span></a>) as <span class="math inline">\(E\left[\log(X)\right]\)</span> where <span class="math inline">\(X\)</span> has density <span class="math inline">\(f(x)\)</span> defined in <a href="#exm-transformations">Example&nbsp;<span>2.3</span></a>.</p>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>While mathematicians distinguish between a derivative <span class="math inline">\(\frac{d}{dx}\)</span> and a partial derivative <span class="math inline">\(\frac{\partial}{\partial x}\)</span>, we do not make that distinction.</p>
</div>
</div>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>A good <a href="https://qiangbo-workspace.oss-cn-shanghai.aliyuncs.com/2018-11-11-common-probability-distributions/distab.pdf">table of common distributions</a> is given in Casella and Berger, a popular text for statistical theory at the graduate level.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>An excellent <a href="http://www.math.wm.edu/~leemis/chart/UDR/UDR.html">summary of the relationships between Distributions</a> was developed by faculty at the College of William and Mary.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./01b-fundamentals.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Essential Probability</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./02a-language.html" class="pagination-link">
        <span class="nav-page-text">Unit II: Language of Data</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>